## 3.1 카프카 기초 다지기 


### 카프카를 구성하는 주요 요소

> 주키퍼 (Zookeeper)

- 아파치 프로젝트 애플리케이션 이름
- 카프카 메타데이터 관리 및 브로커의 정상 상태 (Health Check) 점검 담당

> 카프카 (Kafka) / 카프카 클러스터 (Kafka cluster)

- 아파치 프로젝트 애플리케이션 이름
- 여러 대의 브로커를 구성한 클러스터 의미

> 브로커 (Broker)

- 카프카 애플리케이션이 설치된 서버 또는 노드

> 프로듀서 (Producer)

- 카프카로 메시지를 보내는 역할을 하는 클라이언트 총칭

> 컨슈머 (Consumer)

- 카프카에서 메시지를 꺼내가는 역할을 하는 클라이언트 총칭

> 토픽 (Topic)

- 카프카는 메시지 피드들을 토픽으로 구분
- 각 토픽의 이름은 카프카 내에서 고유

> 파티션 (Partition)

- 병렬 처리 및 고성능을 얻기 위해 하나의 토픽을 여러 개로 나눈 것

> 세그먼트 (Segment)

- 프로듀서가 전송한 실제 메시지가 브로커의 로컬 디스크에 저장되는 파일

> 메시지 (Message) / 레코드 (Record)

- 프로듀서가 브로커로 전송하거나, 컨슈머가 읽어가는 데이터 조각 의미

### 3.1.1 리플리케이션

- 각 메시지들을 여러 개로 복제하여 카프카 클러스터 (여러 대의 브로커) 내 브로커들에 분산시키는 동작 의미
    - 하나의 브로커가 종료되더라도 안전성 유지 가능

> replication-factor

- 카프카 내 리플리케이션 유지 개수
- --replication-factor 1
    - 리플리케이션 : 1개

- --replication-factor 3
    - 원본을 포함한 리플리케이션 : 3개

- replication-factor 수가 커지면, 안정성은 높아지지만, 브로커 리소스를 많이 사용하게 됨
    - 브로커가 3개인 경우, 운영 예시
        - 테스트 / 개발 환경 : replication-factor 1
        - 운영 환경 (로그성 메시지로서 약간의 유실 허용) : replication-factor 2
        - 운영 환경 (유실 미허용) : replication-factor 3

### 3.1.2 파티션

- 토픽 하나를 여러 개로 나눠 병렬 처리가 가능하도록 만든 것
- 파티션 수만큼 컨슈머 연결 가능
- 파티션 번호는 0부터 시작
- 파티션 수는 초기 생성 후 언제든 늘릴 수 있지만, 반대로 파티션 수는 줄일 수 없음
    - 따라서, 초기에 토픽 생성 시, 파티션 수를 작게 생성한 후 메시지 처리량, LAG 등을 모니터링을 통해 점진적으로 늘려가는 방법이 좋음
  > LAG : 프로듀서가 보낸 메시지 수 - 컨슈머가 가져간 메시지 수
    - 프로듀서가 보낸 총 메시지 수 : 5개
    - 컨슈머가 처리한 메시지 수 : 4개
    - LAG : 1개

### 3.1.3 세그먼트

- 프로듀서에 의해 브로커로 전송된 메시지는 토픽의 파티션에 저장
- 각 메시지들은 '세그먼트'라는 로그 파일의 형태로 브로커의 로컬 디스크에 저장
    - 토픽 이름-파티션 번호 포맷으로 저장

## 3.2 카프카의 핵심 개념

### 3.2.1 분산 시스템

- 분산 시스템은 네트워크상에 연결된 컴퓨터들의 그룹 의미
    - 단일 시스템이 갖지 못한 높은 성능 목표
- 장애 대응 탁월
    - 하나의 서버/노드에 장애가 발생하더라도 다른 서버 또는 노드가 처리 가능
    - 부하가 높은 경우, 시스템 확장 가능
- 카프카 또한 브로커를 추가하는 방식으로 확장 가능

### 3.2.2 페이지 캐시

- 카프카는 OS의 페이지 캐시를 활요하는 방식으로 설계
- 페이지 캐시는 디스크에 직접 읽고 쓰는 대신, 물리 메모리 중 애플리케이션이 사용하지 않는 일부 잔여 메모리 활용
    - 디스크 I/O 접근 최소화를 통한 성능 향상
    - 카프카 <=> 페이지 캐시 <=> 디스크

### 3.2.3 배치 전송 처리

- 카프카는 프로듀서, 컨슈머와 통신하며 수많은 메시지를 주고 받는데, 이때 발생하는 수많은 통신을 묶어서 처리 가능하다면, 단건으로 통신할 때에 비해 네트워크 오버헤드 최소화 가능

### 3.2.4 압축 전송

- 카프카는 gzip, snappy, lz4, zstd 등의 압축 타입 지원
- 압축만으로도 네트워크 대역폭이나 회선 비용 등을 줄일 수 있으며, 배치 전송과 결합해 사용한다면 높은 효과
    - 높은 압축률 : gzip, zstd
    - 빠른 응답 속도 : lz4, snappy

### 3.2.5 오프셋

![캡처](https://sookocheff.com/post/kafka/kafka-in-a-nutshell/log-anatomy.png)

- 오프셋 : 파티션의 메시지가 저장되는 위치
- 오프셋은 순차적으로 증가하는 숫자 형태
- 각 파티션에서의 오프셋은 고유한 숫자
- 카프카에서는 오프셋을 통해 메시지의 순서를 보장하고, 컨슈머에서는 마지막까지 읽은 위치를 알 수 있음

### 3.2.6 고가용성 보장

- 카프카는 분산 시스템으로 하나의 서버나 노드가 다운되어도 다른 서버 또는 노드가 장애가 발생한 서버의 역할을 대신 수행 가능
  - 고가용성을 위한 리플리케이션 기능 제공
  - 카프카에서의 리플리케이션 기능은 토픽 자체 복제가 아닌 토픽의 파티션 복제
    - 리더 (Leader) / 팔로워 (Follower) 


> 리플리케이션 팩터 수에 따른 리더와 팔로워 수 

| 리플리케이션 팩터 수 | 리더 수 | 팔로워 수 |
|-------------|---|-------|
| 2           | 1 | 1     |
| 3           | 1 | 2     |
| 4           | 1 | 3     |

- 팔로워 숫자가 많으면, 팔로워의 수만큼 브로커의 디스크 공간 소비
- **카프카에서는 리플리케이션 팩터 수를 3으로 구성하도록 권장**
- 리더
  - 프로듀서, 컨슈머의 읽기, 쓰기 요청 처리
- 팔로워 
  - 오직 리더로부터 리플리케이션 하는 역할

### 3.2.7 주키퍼의 의존성

- 주키퍼는 여러 대의 서버를 앙상블 (클러스터)로 구성하고, 서비스 중인 노드 수가 과반수 이상 유지된다면 지속적인 서비스가 가능한 구조
  - 주키퍼는 반드시 홀수 구성
- 최근 카프카에서 주키퍼 제외 

## 3.3 프로듀서의 기본 동작과 예제 맛보기


### 3.3.1 프로듀서 디자인

![캡처](https://jashangoyal.files.wordpress.com/2019/03/producer.png?w=810)

> ProducerRecord

- 카프카로 전송하기 위한 실제 데이터
  - 필수 :Topic, Value
  - 비필수 : Partition, Key

> send()

- Serializer 
  - Key, Value 를 ByteArray 로 직렬화

- Partitioner
  - ProducerRecord 에서 파티션 지정을 했다면, Partitioner 는 미동작
  - ProducerRecord 에서 파티션 지정하지 않았다면, Key 를 가지고 파티션을 선택하여 레코드 전달
    - 기본 : 라운드 로빈 방식

- 프로듀서 내부적으로 send() 메소드 동작 이후 레코드들을 파티션별로 잠시 저장
  - **프로듀서가 카프카로 전송하기 전, 배치 전송하기 위함**
  - **전송 실패 시 재시도**
    - 지정된 횟수만큼 재시도 실패 시 최종 실패 처리 
    - 전송 성공 시 메타데이터 리턴

### 3.3.2 프로듀서의 주요 옵션

> bootstrap.servers
  - 카프카 클러스터는 마스터 개념이 없기 때문에 클러스터 내 모든 서버가 클라이언트 요청을 받을 수 있음
  - 클라이언트가 카프카 클러스터에 처음 연결하기 위한 호스트, 포트 정보를 나타냄

> client.dns.lookup
  - 하나의 호스트에 여러 IP를 매핑해 사용하는 일부 환경에서 클라이언트가 하나의 IP와 연결하지 못할 경우, 다른 IP로 요청을 시도하는 설정

> acks
  - 프로듀서가 카프카 토픽의 리더 측에 메시지를 전송한 후 요청을 완료하기를 결정하는 옵션
  - 0, 1, all (-1)
  - 0 
    - 빠른 전송 (일부 메시지 손실 발생 가능)
  - 1 
    - 리더가 메시지를 받았는지만 확인, 팔로워의 리플리케이션 여부 미확인
  - all (-1)
    - 팔로워가 메시지를 받았는지 여부 확인 (메시지 손실 미발생)

> buffer.memory
  - 프로듀서가 카프카 서버로 데이터를 보내기 위해 잠시 대기할 수 있는 전체 메모리 바이트
    - **배치 전송, 딜레이**

> compression.type
  - 프로듀서가 메시지 전송 시 선택 가능한 압축 타입
    - none, gzip, snappy, lz4, zstd 등

> enable.idempotence
  - true 설정 시 중복 없는 전송 가능 
    - max.in.flight.requests.per.connection - 5이하 설정 필요 
    - retries - 0이상 설정 필요
    - acks - all 설정 필요

> max.in.flight.requests.per.connection
  - 하나의 커넥션에서 프로듀서가 최대한 ACK 없이 전송 가능한 요청 수 
  - 메시지 순서가 중요할 경우, 1로 설정 권장

> retries 
  - 전송에 실패한 데이터를 다시 보내기 위한 재시도 횟수

> batch.size
  - 동일한 파티션으로 보내는 여러 데이터를 함께 배치로 보내기 위한 사이즈
    - 적절한 배치 크기 설정은 성능 향상에 도움 

> linger.ms
  - 배치 크기에 도달하지 못한 상태에서 linger.ms 에 설정한 제한 시간에 도달한 경우, 메시지 전송

> transactional.id
  - 동일한 TransactionalId 를 정확히 한 번 전송하는 것 보장
    - **enable.idempotence : true 설정 필요**

### 3.3.3 프로듀서 예제

> 프로듀서 전송 방법 3가지
  - 메시지를 보내고 확인하지 않기
  - 동기 전송
  - 비동기 전송

````java
// 메시지를 보내고 확인하지 않기 예제 (ProducerFireForgot.java)
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;

import java.util.Properties;

public class ProducerFireForgot {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "peter-kafka01.foo.bar:9092, peter-kafka02.foo.bar:9092, peter-kafka03.foo.bar:9092"); // 브로커 정보
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer"); // key - StringSerializer 설정 
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer"); // value - StringSerializer 설정

        Producer<String, String> producer = new KafkaProducer<>(props); // 프로듀서 생성
        
        try {
            for (int i = 0; i < 3; i++) {
                // ProducerRecord 객체 생성 (레코드)
                ProducerRecord<String, String> record = new ProducerRecord<>("peter-basic01", "Apache Kafka is a distributed streaming platform - " + i);
                
                // send() 메소드를 통한 메시지 전송
                producer.send(record); // RecordMetadata 리턴을 받지 않기 때문에, 메시지 전송 성공 여부 파악 불가
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            producer.close(); // 프로듀서 종료
        }
    }
}
```` 


````java
// 동기 전송 (ProducerSync.java)
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;

import java.util.Properties;

public class ProducerSync {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "peter-kafka01.foo.bar:9092, peter-kafka02.foo.bar:9092, peter-kafka03.foo.bar:9092"); // 브로커 정보
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer"); // key - StringSerializer 설정 
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer"); // value - StringSerializer 설정

        Producer<String, String> producer = new KafkaProducer<>(props); // 프로듀서 생성
        
        try {
            for (int i = 0; i < 3; i++) {
                // ProducerRecord 객체 생성 (레코드)
                ProducerRecord<String, String> record = new ProducerRecord<>("peter-basic01", "Apache Kafka is a distributed streaming platform - " + i);
                
                // get() 메소드를 통하여 카프카 응답 대기
                // 1. 메시지 전송 성공 시 RecordMetadata 리턴
                // 2. 메시지 전송 실패 시 예외 발생
                RecordMetadata metadata = producer.send(record).get(); // send() 메소드를 통한 메시지 전송

                System.out.println("Topic : %s, Partition : %d, Offset : %d, Key : %s, Received Message : %s\n", metadata.topic(), metadata.partition(), metadata.offset(), record.key(), record.value());
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            producer.close(); // 프로듀서 종료
        }
    }
}
```` 


````java
// 콜백 예제 (PeterProducerCallback.java)
import org.apache.kafka.clients.producer.Callback;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;

public class PeterProducerCallback implements Callback { // 콜백을 위한 Callback 구현 
    
    private ProducerRecord<String, String> record;
    
    public PeterProducerCallback(ProducerRecord<String, String> record) {
        this.record = record;
    }
    
    @Override
    public void onCompletion(RecordMetadata metadata, Exception e) {
        // 예외 발생 시 예외 처리 별도 구현 필요
        if (e != null) {
            e.printStackTrace();
        } else {
            System.out.println("Topic : %s, Partition : %d, Offset : %d, Key : %s, Received Message : %s\n", metadata.topic(), metadata.partition(), metadata.offset(), record.key(), record.value());    
        }
    }
}
```` 

````java
// 비동기 전송 (ProducerAsync.java)
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;

import java.util.Properties;

public class ProducerAsync {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "peter-kafka01.foo.bar:9092, peter-kafka02.foo.bar:9092, peter-kafka03.foo.bar:9092"); // 브로커 정보
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer"); // key - StringSerializer 설정 
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer"); // value - StringSerializer 설정

        Producer<String, String> producer = new KafkaProducer<>(props); // 프로듀서 생성

        try {
            for (int i = 0; i < 3; i++) {
                // ProducerRecord 객체 생성 (레코드)
                ProducerRecord<String, String> record = new ProducerRecord<>("peter-basic01", "Apache Kafka is a distributed streaming platform - " + i);

                // 프로듀서에 콜백 객체를 포함하여 메시지 전송  
                producer.send(record, new PeterProducerCallback(record));
            }
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            producer.close(); // 프로듀서 종료
        }
    }
}
````

## 컨슈머의 기본 동작과 예제 맛보기

### 3.4.1 컨슈머의 기본 동작 
