## 카프카 클러스터 환경 구축하기
> 클러스터 구성 
- 카프카는 1대 이상의 브로커로 이루어진 '카프카 클러스터', '프로듀서', '컨슈머', 카프카 클러스터를 실행하는 '카프카 클라이언트'로 구성

> 3대의 서버로 카프카 클러스터를 구축할 때의 동작 환경

|호스트명|역할|설명|
|---|---|---|
|kafka-broker01|브로커|
|kafka-broker02|브로커|서버 3대에서 카프카 클러스터를 구축한다.|
|kafka-broker03|브로커| 
|producer-client|프로듀서|카프카에 메시지를 송신한다.|
|consumer-client|컨슈머|카프카에서 메시지를 수신한다.|
|kafka-client|카프카 클라이언트|

> 서버 1대만으로 카프카 클러스터를 구축할 때의 동작 환경
- 해당 구성은 카프카가 갖는 규모나 내장애성의 장점을 살릴 수 없기 때문에 테스트 환경 등 제약 환경에서만 사용 

|호스트명|역할|설명|
|---|---|---|
|kafka-server|카프카 클러스터/클라이언트|브로커, 프로듀서, 컨슈머, 카프카 클라이언트의 모든 역할을 담당|

## 각 서버의 소프트웨어 구성
- 카프카 클러스터는 1대 이상의 브로커와 주키퍼(Zookeeper)로 구성
    - 여기서는 브로커와 주키퍼를 동일 서버에 함께 설치하는 구성으로 카프카 클러스터를 구성
    - 클러스터를 구성하는 브로커 3대 모두에 카프카 브로커와 주키퍼 설치

- 주키퍼는 지속적인 서비스를 위해 항상 과반수가 동작하고 있어야 한다
    - 데이터 쓰기가 과반수 서버에 성공했을 때 쓰기 성공으로 간주하기 때문
    - 따라서, 과반수를 입증하기 위해 주키퍼 서버는 홀수의 노드 수가 바람직
    - 주키퍼 또한 사용 환경에 따라 브로커와 함께 설치하기도 하고, 하둡과 같은 다른 미들웨어와 공유하기 위해 별도로 구축하기도 함

- 카프카 클라이언트 서버에는 카프카 클러스터 조작에 필요한 도구 설치

## 카프카의 대표적인 배포판
|패키지/배포판|개발사|URL|
|---|---|---|
|커뮤니티 버전|아파치소프트웨어재단|http://kafka.apache.org|
|Confluent Platform|컨플루언트|http://www.confluent.io|
|Cloudera's Distribution of Apache Kafka(CDK)|클라우데라|http://cloudera.com|
|Hortonworks Data Platform(HDP)|호튼웍스|http://hortonworks.com|

## OS설치 - 공통
- 여러대의 서버로 구축할 경우, 절 제목에서 '공통'과 '여러 대의 경우', 1대만으로 구축하는 경우는 '공통'만 실행
- 카프카와 컨플루언트 플랫폼은 리눅스와 MAC OS에서 동작 (* MAC에서는 개발 및 테스트 목적으로만 지원)

## JDK 설치 - 공통

## 컨플루언트 플랫폼 레포지토리 등록 - 공통
````
$ sudo rpm --import https://packages.confluent.io/rpm/5.0/archive.key
````

````
$ yum clean all
````

````
// confluent-kafka-xxxxx 패키지 확인
$ yum list | grep confluent
````

## 카프카 설치 - 공통
````
$ sudo yum install confluent-platform-oss-2.11
```` 

## 브로커의 데이터 디렉토리 설정 - 공통
- /etc/kafka/server.properties 를 열어서 아래와 같이 수정
- 컨플루언트 플랫폼의 기본값은 '/var/lib/kafka' 이지만, Oracle JDK를 사용하는 경우 '/var/lib/kafka/data' 를 이용해야 함 
````
(생략)
log.dirs=/var/lib/kafka/data <- 이미 작성되어 있는 것을 수정
(생략)
````
   
- 컨플루언트 플랫폼에 포함되어 있는 스크립트로 브로커를 시작하는 사용자가 'cp-kafka'이므로 디렉토리의 소유자도 여기에 맞게 변경
````
$ sudo mkdir /var/lib/kafka/data
$ sudo chown cp-kafka:confluent /var/lib/kafka/data
````

## 카프카 클러스터 실행 
- 주키퍼와 브로커 중에서 '주키퍼'를 먼저 실행한 후에 '브로커'를 실행해야 한다
- 주키퍼 Log : /var/log/kafka/zookeeper.out 
- 브로커 Log : /var/log/kafka/server.log 
````
// 주키퍼 실행
$ sudo systemctl start confluent start confluent-zookeeper
````
````
// 브로커 실행
$ sudo systemctl start confluent-kafka
````

## 카프카 클러스터 동작 확인
- 카프카에 들어 있는 도구 Kafka Console Producer와 Kafka Console Consumer를 이용하여 실제 메세지 전송 및 카프카 클러스터가 제대로 메시지를 송수신하는지 여부 확인

#### 토픽 생성
````
// 서버 1대로 카프카 환경을 구축한 경우 (first-test 토픽 생성)
(kafka-client)$ kafka-topics --zookeeper kafka-server:2181 --create --topic first-test --partitions 3 --replication-factor 1
````
````
// 서버 3대로 클러스터를 구축한 경우 (first-test 토픽 생성)
(kafka-client)$ kafka-topics --zookeeper kafka-broker01:2181,kafka-broker02:2181,kafka-broker03:2181 
 --create --topic first-test --partitions 3 --replication-factor 3
 
출력 : Created topic "first-test"
````
> --zookeeper 
- 카프카 클러스터를 관리하고 있는 주키퍼로의 접속 정보 지정

> --create
- 토픽 작성 (--list : 토픽 목록 확인, --delete : 토픽 삭제)

> --topic
- 작성하는 토픽 이름 지정

> --partitions
- 작성하는 토픽의 파티션 수 지정

> --replication-factor
- 작성하는 토픽의 레플리카의 수 지정 (3대의 서버를 사용하는 경우 '3' 지정) 
- Replication-Factor는 카프카 클러스터의 브로커 수 이하여야 함 (서버가 1대인 카프카 클러스터에서 Replication-Factor를 '3'으로 지정하면 오류 발생)

#### 2. 토픽 생성 확인
````
// 여러 대의 서버에서 클러스터를 구축한 경우, 토픽 생성 확인
(kafka-client)$ kafka-topics --zookeeper kafka-broker01:2181,kafka-broker02:2181,kafka-broker03:2181 --describe --topic first-test

출력 
Topic:first-test PartitionCount:3 ReplicatrionFactor:3 Config:
Topic: first-test Partition: 0 Leader: 1 Replicas: 1,2,3 Isr: 1,2,3
Topic: first-test Partition: 1 Leader: 2 Replicas: 2,3,1 Isr: 2,3,1
Topic: first-test Partition: 2 Leader: 3 Replicas: 3,1,2 Isr: 3,1,2
````

> Topic, PartitionCount, ReplicationFactor
- 지정한 토픽의 이름, 파티션 수, Replication-Factor가 표시

> Leader
- 각 파티션의 현재 Leader Replica가 어떤 브로커에 존재하고 있는지 표시
- 여기에 표시되는 번호는 각 브로커에 설정한 브로커 ID

> Replicas
- 각 파티션의 레플리카를 보유하고 있는 브로커의 목록 표시

> Isr
- In-Sync Replicas의 약자로 복제본 중 Leader Replica와 올바르게 동기가 실행된 복제본을 보유하고 있는 브로커 목록 표시
- 장애와 같이 특정 이유로 Leader Replica의 동기화가 실행되지 않은 레플리카는 In-Sync Replicas에 포함되지 않음
- Leader Replica 자신은 In-Sync Replicas에 포함

#### 3. Kafka Console Producer 실행
````
// 여러 대의 서버에서 클러스터를 구축한 경우 (Producer 실행)
(producer-client)$ kafka-console-producer --broker-list kafka-broker01:9092,kafka-broker02:9092,kafka-broker03:9092 --topic first-test
````
````
// 서버 1대로 카프카 환경을 구축한 경우 (Producer 실행)
// TODO : 확인 필요
````  

> --broker-list
- 메시지를 보내는 카프카 클러스터의 브로커 호스트명과 포트 번호 지정
- 여러 개가 있을 경우 쉼표로 연결 (Default 포트 : 9092)

> --topic
- 메시지 송신처가 되는 토픽 지정

#### 4. Kafka Console Consumer 실행
````
// 여러 대의 서버에서 클러스터를 구축한 경우 (Consumer 실행)
(consumer-client)$ kafka-console-consumer --bootstrap-server kafka-broker01:9092,kafka-broker02:9092,kafka-broker03:9092 --topic first-test
````
````
// 서버 1대로 카프카 환경을 구축한 경우 (Consumer 실행)
// TODO : 별도의 콘솔을 열어 실행 .. 확인 필요
````  

> --bootstrap-server
- 메시지를 수신하는 카프카 클러스터의 브로커 호스트명과 포트 번호 지정

> --topic
- 메시지를 수신하는 토픽 지정

#### 5. 동작 확인
- Kafka Console Producer 송신
````
(producer-client)$ kafka-console-producer --broker-list (생략)
> Hello Kafka ! <- 문자열 입력 후 [Enter]
````

- Kafka Console Consumer 수신
````
(consumer-client)$ kafka-console-consumer --bootstrap-server (생략)
Hello Kafka ! <- 받은 메시지가 표시되는 것 확인
````

#### 6. 카프카 클러스터 종료
- 카프카 클러스터 종료는 실행의 역순으로 브로커부터 종료 후 주키퍼를 종료한다.
````
// 브로커 종료
$ sudo systemctl stop confluent-kafka
````

````
// 주키퍼 종료
$ sudo systemctl stop confluent-zookeeper
````