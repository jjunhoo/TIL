## 카프카 기초
1. 메시지 송수신 기본
2. 시스템 구성
3. 분산 메시징을 위한 구조
4. 데이터의 견고함을 담보하는 복제 구조

## 메시지 송수신 기본
카프카의 주요 구성 요소 5가지

> 브로커
- 데이터를 수신, 전달하는 서비스
> 메시지
- 카프카에서 다루는 데이터의 최소 단위 (카프카가 중계하는 로그 한줄 한줄)
- 메시지는 Key, Value 갖음
> 프로듀서
- 데이터의 생산자이며, 브로커에 메시지를 보내는 어플리케이션
> 컨슈머
- 브로커에서 메시지를 취득하는 어플리케이션
> 토픽
- 메시지를 종류(토픽)별로 관리하는 스토리지, 브로커에 배치되어 관리
- 프로듀서와 컨슈머는 특정 토픽을 지정하여 메시지를 송수신

## 시스템 구성

> 브로커
- 하나의 서버(또는 인스턴스) 당 하나의 데몬 프로세스로 동작하여 메시지 수신/전달 요청을 받아드림
- 브로커를 여러 대의 클러스터로 구성 가능하며, 브로커(Resource)를 추가함으로써 수신/전달의 처리량 향상(Scale-Out)이 가능
- 데이터는 모두 디스크로 내보내기(영속화)가 이루어져 디스크의 총 용량에 따라 장기간 데이터를 보존 가능

> 프로듀서/컨슈머 API
- 브로커로 데이터를 보내고, 브로커에서 데이터를 받기 위한 '라이브러리'로 제공
- 프로듀서를 구현하기 위한 API : 프로듀서 API
- 컨슈머를 구현하기 위한 API : 컨슈머 API
- 프로듀서/컨슈머는 브로커처럼 서비스(데몬 프로세스)로 작동하는 프로그램이 아니라 각각의 API는 자바로 제공

> 프로듀서
- 프로듀서 API를 통해서 브로커에 데이터를 송신하기 위해 구현된 어플리케이션
- 프로듀서 기능을 내장하거나 서드 파티의 플러그인 제휴를 통해 제공하는 OSS 도구 종류
    1. Apache Log4j (Kafka Appender)
        - 로그 출력 시 사용하는 자바 기반 로깅 유틸리티 소프트웨어
    2. Apache Flume (Kafka Sink)
        - 다량의 로그 데이터를 효율적으로 수집, 취합, 이동하기 위한 분산형 소프트웨어
    3. Fluentd (fluent-plugin-kafka)
        - 크로스 플랫폼 오픈소스 데이터 수집 소프트웨어
    4. Logstash (logstash-output-kafka)
        - Elasticsearch에서 제공하는 OSS 데이터 수집 엔진    
        
> 컨슈머
- 컨슈머 API를 통해 브로커에서 메시지를 취득하도록 구현된 어플리케이션
- 브로커의 디스크에 보관(영속화)되어 있는 동안은 메시지 취득 가능
- 분산 스트림 처리 OSS 표준 라이브러리
    1. Apache Spark (Spark Streaming + Kafka Integration Guide)
        - 빅데이터 처리를 위한 오픈 소스 클러스터 컴퓨팅 프레임워크
    2. Apache Samza 
        - 스트림 처리용 오픈소스 소프트웨어로 준 리얼 타임 비동기 계산 프레임워크
    3. Apache Flink
        - 스트림 처리용 오픈소스 프레임워크
    4. Apache Flume (Kafka Source)
    5. Fluentd (fluent-plugin-kafka)
    6. Logstash (logstash-input-kafka)
    
> 카프카 메시지 흐름 방식 

- 메시지 흐름 : 프로듀서 -> 브로커 -> 컨슈머
1. PUSH 형
    - 메시지 전달 방향 : 프로듀서 -> 브로커 (프로듀서가 주체) 
2. PULL 형
    - 메시지 전달 방향 : 브로커 -> 컨슈머 (컨슈머에서의 패치 요청)
    - 컨슈머 시스템이 고장이나 유지보수로 정지한 경우에도 브로커에 미치는 영향이 적다
    
> 주키퍼 (ZooKeeper)
- 카프카의 브로커에 있어 분산 처리를 위한 관리 도구
- 주키퍼 클러스터 (주키퍼 앙상블) 의 구조상 3, 5와 같이 홀수로 구성하는 것이 일반적

> 카프카 클라이언트
- 토픽 작성 등 카프카의 동작 및 운영상에 필요한 조작을 실행하는 서버

> 카프카 클러스터
- 주키퍼에 의해 구성된 클러스터 시스템

## 분산 메시징을 위한 구조

> 파티션 
- 토픽에 대한 대량의 메시지 입출력을 지원하기 위해 브로커상의 데이터를 읽고 쓰는 것은 파티션이라는 단위로 분할
- 각 파티션을 브로커에 어떻게 배치하는가에 대한 정보는 브로커 측에 유지

> 컨슈머 그룹
- 카프카는 컨슈머에서의 분산 스트림 처리도 고려해 설계
- 단일 어플리케이션 안에서 여러 컨슈머가 단일 토픽이나 여러 파티션에서 메시지를 취득하는 방법으로 컨슈머 그룹이라는 개념 존재

> 오프셋
- 각 파티션에서 수신한 메시지에는 각각 일련번호가 부여되어 있어서 파티션 단위로 메시지 위치를 나타내는 '오프셋' 이라는 관리 정보를 이용해 컨슈머가 취득하는 메시지의 범위 및 재시도를 제어
    - Log-End-Offset (LEO) : 파티션 데이터의 끝을 나타냄
    - Current Offset : 컨슈머가 어디까지 메시지를 읽었는지 나타냄
        - 컨슈머에서의 데이터 취득을 계기로 업데이트
        - 컨슈머 그룹마다 보관되어 관리/업데이트 
    - Commit Offset : 컨슈머가 어디까지 커밋했는지 나타냄
        - 컨슈머로부터 '여기까지의 오프셋은 처리했다' 는 것을 확인하는 오프셋 커밋 요청을 계기로 업데이트
        - 특정 토픽에 대해 여러 컨슈머 그룹이 메시지를 취득하는 경우, 파티션에 대한 Commit Offset도 컨슈머 그룹 숫자만큼 존재
        
## 메시지 송수신
- 카프카는 송수신 처리량을 높이기 위해 어느 정도 메시지를 축적하여 배치 처리로 송수신하는 기능 또한 제공 (카프카에서는 메시지 단일 송수신이 아닌 처리를 배치라고 총칭)

> 프로듀서의 메시지 송신
- 프로듀서가 토픽의 파티션에 메시지를 송신할 때 버퍼 기능처럼 프로듀서의 메모리를 이용하여 일정량을 축적 후 송신 가능 (Default : 1메시지마다 송신)
- 데이터 송신은 지정한 크기 (batch size) 까지 메시지가 축적되거나, 지정한 대기 시간 (linger.ms) 에 도달하는 것 중 하나를 트리거로 전송

> 컨슈머 메시지 취득
- 컨슈머는 취득 대상의 토픽과 파티션에 대해 Current Offset으로 나타나는 위치에서 마지막으로 취득한 메시지로부터 브로커에서 보관하는 최신 메시지까지 모아서 요청 및 취득
- 메시지의 유입 빈도가 동일한 경우, 컨슈머의 브로커 요청 간격이 길수록 모인 메시지가 많아짐

    > 작은 범위로 요청하는 경우
    - 하나의 요청으로 1개의 메시지를 취득하는 경우, 하나의 메시지마다 Current Offset 업데이트
    > 일정 간격을 두고 요청하는 경우
    - 하나의 요청으로 5개의 메시지를 취득하는 경우, 5개의 메시지만큼 Current Offset 업데이트
    
## 컨슈머의 롤백 
- 컨슈머는 Offset Commit 구조를 이용해 컨슈머 처리 실패, 고장 시 롤백 메시지 재취득 실행
    - 컨슈머쪽에서 처리 중 Offset Commit을 실행하기 전에 컨슈머에서 장애가 발생할 경우, 컨슈머가 장애에서 복귀되면 'Commit Offset' 위치에서부터 재개하며, 메시지를 재취득한다.
    - 주의 : 'Commit Offset' 까지 되돌아온 오프셋 간 메시지에 대한 대처는 후속 어플리케이션에 맡긴다.
        - 메시지 처리 완료 상태에서 Commit Offset 업데이트 직전의 장애의 경우, 동일한 메시지가 재전송되고, 메시지 중복 처리(또는 중복 허용)이 필요
        - Spark Streaming 등 카프카 연계 기능을 제공하는 프레임워크에서는 이를 재실행하는 메커니즘이 있으므로 사용자가 이를 감지하여 직접 재실행 하는 경우는 드뭄

## 메시지 전송 시 파티셔닝
- 프로듀서에서 송신하는 메시지를 어떻게 파티션으로 보낼지 결정하는 파티셔닝 (분할) 기능 제공
- 보내는 메시지에 포함된 Key/Value 중 Key의 명시적인 지정 여부에 따라 2가지 패턴으로 송신

> key의 해시 값을 사용한 송신
- key에 따라 송신처 파티션을 결정하는 로직 (동일한 Key를 가진 메시지는 동일한 ID를 가진 파티션에 송신됨)
- 해시 파티셔닝 이용 시 극단적인 경우, 준비한 파티션 수에 대해 출현하는 Key의 종류가 충분하지 않은 때는 파티션에 편향이 발생하거나 데이터가 송수신되지 않는 파티션이 발생하여 리소스를 부분적으로 사용할 수 없는 상태가 될 수 있음

> 라운드 로빈에 의한 송신 
- 메시지 Key를 지정하지 않고 Null로 한 경우 여러 파티션으로의 메시지 송신을 라운드 로빈 방식으로 실행

## 데이터의 견고성을 높이는 복제 구조
- 카프카는 메시지를 중계함과 동시에 서버 장애 시 수신한 메시지를 잃지 않기 위해 복제(Replication) 구조를 갖춤
- 파티션은 단일 또는 여러 개의 레플리카로 구성되며, 토픽 단위로 레플리카 수를 지정 가능
- 레플리카 중 하나는 'Leader'이며, 나머지는 'Follower' 라고 부름
    - Follower 는 이름대로 Leader로부터 메시지를 계속적으로 취득하여 복제를 유지하도록 동작
    
## 레플리카의 동기 상태
- Leader Replica의 복제 상태를 유지하고 있는 레플리카는 In-Sync Replica로 분류
- 모든 레플리카가 In-Sync Replica로 되어 있지 않은 파티션을 'Under Replicated Partitions' 라고 한다
- 파라미터 'replica.lag.time.max.ms' 에서 정산 시간보다도 오랫동안 복제의 요청 및 복제가 이루어지지 않을 경우 복제 상태를 유지하지 않는 것으로 간주

## 복제 완료 최신 오프셋 (High Watermark)
- High Watermark는 복제가 완료된 오프셋으로 Log End Offset과 동일하거나 오래된 오프셋을 나타냄
    - Leader는 비동기로 계속하여 Follower로 복제
- 컨슈머는 High Watermark까지 기록된 메시지를 취득할 수 있음
    - 컨슈머가 High Watermark에 기록되지 않은 메시지를 취득한 경우, Leader Replica를 갖는 브로커가 복제를 완료하지 않은 타이밍에 고장이 발생하면 그 사이에 취득한 메시지는 두 번 다시 취득할 수 없는 상태가 된다.

## 브로커의 데이터 보관 기간
브로커 파라미터 : cleanup.policy 를 통해 delete/compact 설정 가능

> 오래된 메시지 삭제
- 축적된 메시지 중 오래된 것부터 삭제하며 삭제 트리거에 대해서는 메시지 취득 후 경과 시간, 데이터 크기 2가지로 설정 가능
1. 데이터 취득 후 경과 시간을 트리거로 할 경우
    - 시간, 분, 밀리초 등으로 지정 가능 (지정한 시간보다 오래된 데이터 삭제)
    - Default : 168시간 (1주)
2. 데이터 크기를 트리거로 한 경우
    - 축적 데이터가 지정한 데이터 크기보다 커진 경우 데이터 삭제 
    - Default : -1 (크기 제한 없음)

> 압축 (Compaction)
- 최신 Key 데이터를 남겨두고 중복하는 Key의 오래된 메시지가 삭제

## 메시지 순서 보증