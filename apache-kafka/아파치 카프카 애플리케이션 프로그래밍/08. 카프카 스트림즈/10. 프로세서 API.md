## 프로세서 API

> 프로세서 API 는 스트림즈DSL 보다 투박한 코드를 가지지만, 토폴로지를 기준으로 데이터를 처리한다는 관점에서는 동일한 역할 수행

- 스트림즈DSL은 데이터 처리, 분기, 조인을 위한 다양한 메소드를 제공하지만, 추가 상세 로직의 구현이 필요한 경우, 프로세서 API 활용 필요
- 프로세서 API 에서는 스트림즈DSL에서 사용했던 KStream, KTable, GlobalKTable 개념이 없음
  - 다만, 스트림즈DSL과 프로세서 API를 함께 구현하여 사용 시 활용 가능

> 프로세서 API 구현을 위해 'Processor' 또는 'Transformer' 인터페이스로 구현한 클래스 필요

- Processor 인터페이스

  - 일정 로직이 이루어진 뒤 다음 프로세서로 데이터가 넘어가지 않을 때 사용
- Transformer 인터페이스

  - 일정 로직이 이루어진 뒤 다음 프로세서로 데이터를 넘길 때 사용

````java
// Processor 구현
public class FilterProcessor implements Processor<String, String> {

    private ProcessorContext context;

    @Override
    public void init(ProcessorContext context) {
        this.context = context;
    }

    @Override
    public void process(String key, String value) {
        // 해당 조건인 경우 Topology 의 addSink 프로세스 실행
        if (value.length() > 5) {
            context.forward(key, value);
        }

        context.commit();
    }

    @Override
    public void close() { }
}
````

````java
public class SimpleKafkaProcessor {
    ...
    public static void main(String[] args) {
        ...
        Topology topology = new Topology();

        topology.addSource("Source", STREAM_LOG) // Source 프로세서를 통해 'STREAM_LOG' 토픽 데이터 추출
            .addProcessor("Process",    // 위에서 만든 'FilterProcessor' 의 process() 메소드를 사용하여 특정 조건인 경우, forward() 수행 (이후 프로세스인 addSink 수행)
                () -> new FilterProcessor(),
                "Source")
            .addSink("Sink", STREAM_LOG_FILTER, "Process"); // Sink 프로세서를 통해 'STREAM_LOG_FILTER' 토픽에 데이터 저장

        KafkaStreams streaming = new KafkaStreams(topology, props);
        streaming.start();
    }
}
````
