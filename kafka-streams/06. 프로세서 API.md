## Processor API

- Processor API 는 카프카 스트림즈의 하위 수준 API 로서 `상위 수준 DSL 보다 적은 추상화`를 갖고 있으며 `명령형 프로그래밍 방식` 사용
- 코드는 조금 더 길어질 수 있지만, 토폴로지에서의 데이터 흐름, 스트림 프로세서들의 관계, 상태의 생성과 유지 보수, 특정 연산의 수행 시간과 같은 특징들을 세밀하게 제어 가능

### 1. Processor API 는 언제 사용해야 할까 ?

> Processor API 사용 목적

1. 레코드의 메타데이터 (토픽, 파티션, 오프셋 정보, 레코드 헤더 등) 접근
2. 주기적인 함수 스케줄링
3. 레코드를 하위 스트림 프로세서로 넘길 때, 사용 가능한 세세한 제어
4. 상태 저장소에 대한 보다 세분화된 접근
5. DSL 을 사용할 때, 마주칠 수 있는 제약들을 뛰어넘을 수 있는 기능

> Processor API 단점

1. 장황한 코드로 인한 유지 보수 비용 증가로 가독성 저하
2. 다른 프로젝트 관리자가 진입하기 어려운 높은 장벽
3. DSL 특징 또는 추상화에 대한 우발적 재창조, 이상한 문제 구조화, 성능 함정과 같은 문제 발생 가능성
   - 이상한 문제 구조화 : 표현력이 떨어지고, 연산자들이 적어지게 되면 문제 구조화의 표준화가 멀어지며, 사람들과의 소통을 어렵게 만든다.
   - 성능 함정 : 지나친 커밋과 상태 저장소 접근은 성능에 영향을 미칠 수 있다.

> 튜토리얼 소개 : IoT 디지털 트윈 서비스

- 해상 풍력 발전 단지에서 사용할 `디지털 트윈 서비스` 구축을 위해 Processor API 사용
- 디지털 트윈 서비스는 카프카 스트림즈를 사용할 수 있는 적절한 예
  - 대용량 센서 데이터 수집 및 처리
  - 상태 저장소를 이용한 물리적 개체의 상태 캡처
  - 대화형 쿼리를 통한 상태 노출

> 예

- 상황

  - 40개의 풍력 터빈을 가지고 있는 풍력발전소가 있다.
  - 하나의 터빈이 현재 상태를 보고할 때마다, `키-값 저장소에 정보를 저장`한다.
  - 디바이스 ID 는 레코드 키를 통해 전달된다.
    - 아래 예제 레코드는 ID : abc123 의 디바이스와 관련이 있다.
  - 특정 풍력 터빈과 상호 동작은 직접 이루어지지 않는다.
    - IoT 디바이스들은 주기적으로 오프라인 상태가 될 수 있으므로, 물리적 디바이스의 `디지털 복사본 (트윈) 과 상호 동작`하면 고가용성 달성 및 오류 저하 가능
- 상태 레코드 값 예제

````json
{
    "timestamp": "2020-11-23T09:02:00.000Z",
    "wind_speed_mph": 40,
    "temperature_fahrenheit": 60,
    "power": "ON"
}
````

- 디지털 트윈 레코드
  - 전원 상태를 ON 에서 OFF 로 설정하고자 한다면, 터빈에 직접 신호를 보내는 대신 디지털 트윈에 희망하는 상태를 설정

````json
{
    "desired": {
        "timestamp": "2020-11-23T09:02:01.000Z",
        "power": "OFF"
    },
    "reported": {
        "timestamp": "2020-11-23T09:00:01.000Z",
        "windSpeedMph": 68,
        "power": "ON"
    }
}
````

![img78.png](image/img78.png)

1. 각 풍력 터빈은 환경 센서들을 장착하고 있다. 그리고 이 데이터는 터빈 자신의 메타데이터와 함께 주기적으로 `reported-state-events` 에 전송된다.
   - 사용자 또는 프로세스가 터빈의 전원 상태를 변경하고자 할 때마다 `desired-state-events` 토픽에 데이터 전송한다.
2. 환경 센서 데이터는 `reported-state-events` 토픽으로 전송하므로, 각 터빈이 보고한 풍속이 안전 운영 수준을 초과하는지 여부를 판단하는 스트림 프로세서 추가
   - 만약 안전 운영 수준 초과 시, 자동으로 셧다운 신호 생성



3-1. 첫 번째, 두 이벤트 종류 (reported, desired) 는 디지털 트윈 레코드로 결합
   - 해당 레코드들을 처리한 후 영구적인 키-값 저장소인 `digital-twin-store` 에 저장



3-2. 두 번째, 7일 이상 업데이트 되지 않은 오래된 디지털 트윈 레코드 코드를 정리하는 punctuator 함수를 주기적으로 스케줄링



4. 각 디지털 트윈 레코드는 분석 목적으로 `digital-twins` 토픽으로 전송
5. 카프카 스트림즈의 대화형 쿼리 기능을 통해 디지털 트윈 레코드 노출
   - 몇 초마다 풍력 터빈의 마이크로 컨트롤러는 카프카 스트림즈가 노출한 희망 상태를 자신의 상태로 동기화 시도

> 각 소스 토픽의 예제 레코드와 데이터 모델

- 토픽 : reported-state-events, desired-state-events

````json
// 'reported-state-events' 예제 레코드
{
    "timestamp": "...",
    "wind_speed_mph": 40,
    "power": "ON"
}
````

````json
// 'desire-state-events' 예제 레코드
{
    "timestamp": "...",
    "power": "OFF"
}
````

````java
// 데이터 클래스
public class TurbineState {
    private String timestamp;
    private Double windSpeedMph;

    public enum Power { ON, OFF }

    public enum Type { DESIRED, REPORTED }

    private Power power;
    private Type type;

}
````

> 디지털 트윈 레코드 데이터 모델

````json
{
    "desired": {
        "timestamp": "2020-11-23T09:02:01.000Z",
        "power": "OFF"
    },
    "reported": {
        "timestamp": "2020-11-23T09:00:01.000Z",
        "windSpeedMph": 68,
        "power": "ON"
    }
}
````

````java
// 데이터 클래스
public class DigitalTwin {
    private TurbineState desired;
    private TurbineState reported;
    ...
}
````

> 디지털 트윈과 터빈 상태 레코드를 위한 Serdes

````java
public class JsonSerdes {

    // DigitalTwin Serde 반환 메소드
    public static Serde<DigitalTwin> DigitalTwin() {
        JsonSerializer<DigitalTwin> serializer = new JsonSerializer<>();
        JsonDeserializer<DigitalTwin> deserializer = new JsonDeserializer<>(DigitalTwin.class);

        return Serdes.serdeFrom(serializer, deserializer);
    }

    // TurbineState Serde 반환 메소드
    public static Serde<TurbineState> TurbineState() {
        JsonSerializer<TurbineState> serializer = new JsonSerializer<>();
        JsonDeserializer<TurbineState> deserializer = new JsonDeserializer<>(TurbineState.class);

        return Serdes.serdeFrom(serializer, deserializer);
    }
}
````

### 2. 소스 프로세서 추가

````java
Topology builder = new Topology(); // 1

builder.addSource( // 2
    "Desired State Events", // 3
    Serdes.String().deserializer(), // 4
    JsonSerdes.TurbineState().deserializer(), // 5
    "desired-state-events" // 6
);

builder.addSource(
    "Reported State Events",
    Serdes.String().deserializer(),
    JsonSerdes.TurbineState().deserializer(),
    "reported-state-events"
);
````

1. 토폴로지 생성 및 소스, 싱크, 스트림 프로세서 추가/연결
2. 소스 프로세서 생성

  - `오프셋 재설정 전략`, `토픽 패턴` 등 지원
3. 소스 프로세서 이름

  - 카프카 스트림즈 내부에서 소스 프로세서 이름들을 토폴로지 순서로 정렬한 맵에 저장
  - 각 프로세서는 고유한 이름 필요
  - 자식 프로세서를 연결할 때 사용
4. Key Desializer

  - DSL 은 Serdes (Serializer, Deserializer 를 모두 포함하는 객체) 을 사용하지만, Processor API 에서는 오직 `Deserializer` 만 사용
5. Value Desializer

  - 레코드 값을 TurbineState 객체로 변환하기 위한 커스텀 Serdes 사용
6. 소스 프로세서가 소비하는 토픽명

### 3. 상태가 없는 스트림 프로세서 추가

> 특정 터빈에서 기록한 풍속이 안전 운영 수준 (65mph) 을 초과할 때마다 셧다운 신호를 자동으로 생성할 것을 요구

````java
builder.addProcessor(
  "High Winds Flatmap Processor", // 1
  HighWindsFlatmapProcessor::new, // 2
  "Reported State Events" // 3
);
````

1. 스트림 프로세서 이름
2. Processor 인스턴스를 반환하는 함수 인터페이스인 ProcessSuplier 지정
3. 부모 프로세서 이름

- 스트림 프로세서는 하나 이상의 부모 노드와 연결 가능

### 4. 상태가 없는 프로세서 생성

> Processor API 에서 addProcessor 메소드를 사용할 때마다 스트림의 레코드들을 처리하고 변환하는 `Processor 인터페이스`를 구현해야 한다.

- Processor 인터페이스 메소드
  1. Processor 가 최초 생성될 때 호출
  2. 프로세서가 새 레코드를 받을 때마다 호출되며, 레코드 단위 데이터 변환/처리 로직을 포함
  3. 연산자가 종료될 때마다 카프카 스트림즈가 close 메소드 호출

````java
public interface Processor<K, V> {
  void init(ProcessorContext context); // 1
  void process(K key, V value); // 2
  void close(); // 3
}
````

> 위험 풍속을 감지하는 Processor 구현

````java
public class HighWindsFlatmapProcessor implements Processor<String, TurbineState, String, TurbineState> { // 1

  private ProcessorContext<String, TurbineState> context;

  @Override
  public void init(ProcessorContext<String, TurbineState> context) { // 2
    this.context = context; // 3
  }

  @Override
  public void process(Record<String, TurbineState> record) {
    TurbineState reported = record.value();
    context.forward(record); // 4

    if (reported.getWindSpeedMph() > 65 && reported.getPower() == Power.ON) { // 5
      TurbineState desired = TurbineState.clone(reported); // 6
      desired.setPower(Power.OFF);
      desired.setType(Type.DESIRED);

      Record<String, TurbineState> newRecord = new Record<>(record.key(), desired, record.timestamp()); // 7
      context.forward(newRecord); // 8
    }
  }

  @Override
  public void close() {

  }
}
````

1. 처음 <String, TurbineState, ..., ...> 은 `입력 키와 값 타입` 지정, 이후 <..., ... String, TurbineState> 은 `출력 키와 값 타입` 지정
2. ProcessorContext 인터페이스의 제네릭들은 `출력 키와 값 타입` 지정
3. ProcessorContext 를 인스턴스 속성으로 저장
4. 레코드를 하위 스트림 프로세서로 보내고 싶을 때마다, ProcessorContext 인스턴스의 forward 메소드 호출
5. 터빈이 셧다운 신호를 보낼 조건을 만족하는지 확인 (안전 임계값, 전원)
6. 셧다운 신호 만족 시, 희망 전원 상태를 'OFF' 로 하는 새로운 레코드 생성
7. 상태 저장소에서 저장했던 희망하는 상태를 포함하는 출력 레코드 생성
8. 새로운 레코드를 context.forward 메소드를 호출하여 하위 스트림 프로세서로 전달

### 5. 상태가 있는 프로세서 생성

> 한 풍력 터빈의 레코드들은 각기 다른 시간에 도착하므로, 각 터빈마다 보고한 상태 레코드와 희망하는 상태 레코드를 기억하려면 상태가 있는 처리 필요

````java
// 상태가 있는 프로세서에 필요한 StoreBulder 생성
StoreBulder<KeyValueStore<String, DigitalTwin>> storeBuilder = Stores.keyValueStoreBuilder(
    Stores.persistentKeyValueStore("digital-twin-store"),
    Serde.String(),
    JsonSerdes.DigitalTwin()
);
````

````java
// Processor 인터페이스 구현
builder.addProcessor(
  "Digital Twin Processor", // 1
  DigitalTwinProcessor::new, // 2
  "High Winds Flatmap Processor", "Desired State Events" // 3
);
````

1. 스트림 프로세서 이름
2. Processor 인스턴스를 얻을 때 사용하는 ProcessorSupplier 메소드
3. 부모 프로세서의 이름들

````java
// 토폴로지에 새로운 상태 저장소 추가
builder.addStateStore(
  storeBuilder,
  "Digital Twin Processor" // 해당 저장소를 접근해야 하는 프로세서 이름
);
````

````java
// 상태가 있는 프로세서 구현 (DigitalTwinProcessor)
// 상태 저장소와 상호 동작 필요
public class DigitalTwinProcessor implements Processor<String, TurbineState, String, TurbineState> { // 1

  private ProcessorContext<String, DigitalTwin> context;
  private keyValueStore<String, DigitalTwin> kvStore;

  @Override
  public void init(ProcessorContext<String, DigitalTwin> context) { // 2
    this.context = context; // 3
    this.kvStore = (KeyValueStore) context.getStateStore("digita-twin-store"); // 4
  }

  @Override
  public void process(Record<String, TurbineState> record) {
    String key = record.key(); // 5
    TurbineState value = record.value();
    DigitalTwin digitalTwin = kvStore.get(key); // 6

    if (digitalTwin == null) { // 7
      digitalTwin = new DigitalTwin();
    }

    if (value.getType() == Type.DESIRED) { // 8
      digitalTwin.setDesired(value);
    } else if (value.getType() == Type.REPORTED) {
      digitalTwin.setReported(value);
    }

    kvStore.put(key, digitalTwin); // 9

    Record<String, DigitalTwin> newRecord = new Record<>(record.key(), digitalTwin, record.timestamp()); // 10
    context.forward(newRecord);
  }

  @Override
  public void close() {

  }
}
````

1. 처음 <String, TurbineState, ..., ...> 은 `입력 키와 값 타입` 지정, 이후 <..., ... String, TurbineState> 은 `출력 키와 값 타입` 지정
2. ProcessorContext 인터페이스의 제네릭들은 `출력 키와 값 타입` 지정
3. ProcessorContext 를 인스턴스 속성으로 저장
4. ProcessorContext 의 getStateStore 메소드는 이전에 스트림 프로세서에 추가했던 상태 저장소를 가져올 수 있게 해준다.
  - 레코드를 처리할 때마다 이 상태 저장소와 직접 상호 동작
5. 입력 레코드의 키와 값 추출
6. 현재 레코드 키에 해당하는 값을 찾기 위해 키-값 저장소 사용
  - 만약, 이전에 해당 키를 처리한 적이 있는 경우, 이전에 저장했던 디지털 트윈 레코드 반환
7. 키-값 저장소 조회 시, 결과가 없는 경우, 인스턴스 생성
8. 현재 레코드 타입에 따라 적절한 값을 디지털 트윈 레코드에 설정
9. 키-값 저장소에 put 메소드를 사용하여 상태 저장소에 디지털 트윈 레코드 직접 저장
10. 상태 저장소에 저장했던 디지털 트윈 인스턴스를 포함하는 출력 레코드 생성
11. 출력 레코드를 하위 스트림 프로세서로 전달

### 6. 구두점으로 주기적인 함수 호출

- 경우에 따라 카프카 스트림즈 어플리케이션에서 주기적으로 수행하는 태스크가 필요한 경우가 있다.
- `ProcessorContext#schedule` 메소드로 수행할 태스크 스케줄링 가능
  - 예제 : 최근 7일 동안 상태 업데이트가 발생하지 않은 모든 디지털 트윈 레코드 삭제 (키-값 저장소)
  - 이러한 터빈들은 더 이상 활성 상태가 아니거나 장기간 유지 보수 상태에 있다고 가정

> 카프카 스트림즈에서 사용 가능한 구두점 타입 (실행 시점 전략)

- 스트림 시간
  - Enum
    - PunctuationType.STREAM_TIME
  - 설명
    - 스트림 시간은 특정 토픽 파티션에서 관찰한 타임스탬프 중 가능한 한 큰 타임스탬프이다.
    - 초기에는 알 수 없고 증가하거나 현재 시간에 머물러 있기만 한다.
    - 새로운 데이터가 들어와야 증가하므로 이 구두점 종류를 사용하고자 할때는 데이터가 지속적으로 들어와야 한다. 그렇지 않으면 함수 실행이 되지 않는다.
- 벽시계 시간
  - Enum
    - PunctuationType.WALL_CLOCK_TIM
  - 설명
    - 로컬 시스템 시간으로 컨슈머의 poll 메소드를 호출할 때마다 증가한다.
    - 시간을 얼마나 자주 업데이트할지에 대한 상한 값은 StreamsConfig#POLL_MS_CONFIG 설정으로 한다.
    - 해당 설정은 새로운 데이터를 위해 대기하는 최대 시간을 지정한다.
    - 이 구두점을 사용하면 새로운 메시지들이 도착하는지에 관계없이 주기적인 함수를 계속 실행할 수 있다.

> 예제 : 새로운 데이터가 도착하는 것에 의존하지 않기 때문에 `벽시계 시간` 사용

````java
public class DigitalTwinProcessor implements Processor<String, TurbineState, String, DigitalTwin> {

  private Cancellable punctuator; // 1

  ...

  @Override
  public void init(ProcessorContext<String, DigitalTwin> context) {
    punctuator = this.context.schedule(
      Duration.ofMinutes(5),
      PunctuationType.WALL_CLOCK_TIME, this::enforceTtl // 2
    );
  }

  @Override
  public void close() {
    punctuator.cancel(); // 3
  }

  public void enforceTtl(Long timestamp) {
    try (KeyValueIterator<String, DigitalTwin> iter = kvStore.all()) { // 4
      while(iter.hasNext()) {
        KeyValue<String, DigitalTwin> entry = iter.next();
        TurbineState lastReportedState = entry.value.getReported(); // 5

        if (lastReportedState == null) {
          continue;
        }

        Instant lastUpdated = Instant.parse(lastReportedState.getTimestamp());
        long daysSinceLastUpdate = Duration.between(lastUpdated, Instant.now()).toDays(); // 6

        if (daysSinceLastUpdate >= 7) {
          kvStore.delete(entry.key); // 7
        }
      }
    }
  }
}
````

1. 구두점 함수 스케줄링 시, 나중에 스케줄한 함수를 중지할 때 사용할 수 있는 Cancellable 객체 반환
2. 벽시계 시간 기준으로, 매 5분마다 주기적인 함수를 실행하도록 스케줄링하고, 반환된 Cancellable 객체를 punctuator 로 저장
3. 프로세서 종료 시 (카프카 스트림즈 어플리케이션 종료 시), punctuator 취소
4. 매 함수 호출마다, 상태 저장소에서 각 값을 조회
5. 현재 레코드의 마지막 보고 상태 추출
6. 마지막 상태 보고 후 며칠이 지났는지 판단
7. 오래된 레코드를 상태 저장소에서 삭제

### 6. 레코드 메타데이터 접근

- DSL 사용 시에는 보통 레코드의 키와 값만 접근 가능하다.
- Processor API 사용 시, DSL 에는 노출되지 않는 레코드 관련 많은 정보 접근 가능
- init(), close() 함수가 호출되는 시점에는 현재 레코드가 없으므로 메타데이터를 추출하지 못하며, process() 함수에서만 사용 가능

> 레코드 메타데이터 접근 메소드

- 레코드 헤더들
  - context.headers()
- 오프셋
  - context.offset()
- 파티션
  - context.partition()
- 타임스탬프
  - context.timestamp()
- 토픽
  - context.topic()

> 예제 : 레코드 헤더에 추가적인 메타데이터 주입

````java
Headers headers = context.headers();
headers.add("Hello", "world".getBytes(StandardCharsets.UTF_8)); // 1
headers.remove("goodbye"); // 2
headers.toArray(); // 3
````

1. hello 라는 이름으로 헤더 추가 (하위 스트림 프로세서로 전파)
2. goodbye 라는 헤더 제거
3. 가능한 모든 헤더를 배열로 조회

### 7. 싱크 프로세서 추가하기

````java
builder.addSink(
    "Digital Twin Sink", // 싱크 노드 이름
    "digital-twins", // 출력 토픽 이름
    Serdes.String().serializer(), // 키 Serializer
    JsonSerdes.DigitalTwin().serializer(), // 값 Serializer
    "Digital Twin Processor"); // 싱크에 연결할 하나 이상의 부모 노드 이름
````

### 8. 대화형 쿼리

- 대화형 쿼리 관점에서 Processor API는 DSL 사용과 동일

````java
// 디지털 트윈 레코드를 노출하는 REST 서비스 예제
class RestService {
  private final HostInfo hostInfo;
  private final KafkaStreams streams;

  RestService(HostInfo hostInfo, KafkaStreams streams) {
    this.hostInfo = hostInfo;
    this.streams = streams;
  }

  ReadOnlyKeyValueStore<String, DigitalTwin> getStore() {
    return streams.store(StoreQueryParameters.fromNameAndType("digital-twin-store", QueryableStoreTypes.keyValueStore()));
  }

  void start() {
    Javalin app = Javalin.create().start(hostInfo.port());
    app.get("/devices/:id", this::getDevice);
  }

  void getDevice(Context ctx) {
    String deviceId = ctx.pathParam("id");
    DigitalTwin latestState = getStore().get(deviceId);
    ctx.json(latestState);
  }
}
````

### 9. 모두 조립하기

````java
Topology builder = new Topology();

builder.addSource( // 1
    "Desired State Events",
    Serdes.String().deserializer(),
    JsonSerdes.TurbineState().deserializer(),
    "desired-state-events"
);

builder.addSource( // 2
    "Reported State Events",
    Serdes.String().deserializer(),
    JsonSerdes.TurbineState().deserializer(),
    "reported-state-events"
);

builder.addProcessor( // 3
  "High Winds Flatmap Processor",
  HighWindsFlatmapProcessor::new,
  "Reported State Events"
);

builder.addProcessor( // 4
  "Digital Twin Processor",
  DigitalTwinProcessor::new,
  "High Winds Flatmap Processor",
  "Desired State Events"
);

StoreBulder<KeyValueStore<String, DigitalTwin>> storeBuilder = Stores.keyValueStoreBuilder( // 5
    Stores.persistentKeyValueStore("digital-twin-store"),
    Serde.String(),
    JsonSerdes.DigitalTwin()
);

builder.addStateStore(storeBuilder, "Digital Twin Processor"); // 6

builder.addSink( // 7
    "Digital Twin Sink",
    "digital-twins",
    Serdes.String().serializer(),
    JsonSerdes.DigitalTwin().serializer(),
    "Digital Twin Processor");
````

1. 'desired-state-events' 토픽으로부터 데이터를 소비하는 'Desired State Events' 라는 이름의 소스 프로세서 생성
2. 'reported-state-events' 토픽으로부터 데이터를 소비하는 'Reported State Events' 라는 이름의 소스 프로세서 생성
3. 높은 풍속 감지 시, 셧다운 신호를 생성하는 High Winds Flatmap Processor 라는 이름의 스트림 프로세서 추가
  - 해당 프로세서는 'Reported State Events' 프로세서로부터 이벤트 수신
  - 해당 프로세서는 입력과 출력 레코드의 수의 관계가 1:N 이므로 DSL 의 flatMap 연산과 같음
4. 'High Winds Flatmap Processor' 와 'Desired State Events' 양쪽에서 내보낸 데이터를 이용하여 디지털 트윈 레코드를 생성하는 'Digital Twin Processor' 스트림 프로세서 추가
  - 여러 소스로부터 데이터를 가져오므로 DSL 의 'merge' 연산과 동일
  - 또한 해당 프로세서는 상태가 있으므로 DSL의 집계 테이블과 동일
5. 카프카 스트림즈가 'Digital Twin Processor' 에서 접근 가능한 영구적인 키-값 저장소를 구축할 떄 사용할 수 있는 StoreBuilder 생성을 위해 Stores 팩토리 클래스 이용
6. 토폴리지에 상태 저장소를 추가하고 이를 'Digital Twin Processor' 노드에 연결
7. 모든 'Digital Twin Processor' 노드에서 내보낸 디지털 트윈 레코드를 'digital-twins' 라는 출력 토픽으로 쓰는 'Digital Twin Sink' 라는 이름의 싱크 프로세서 생성

> 어플리케이션 실행 및 테스트 데이터 카프카 클러스터 전송 후 디지털 트윈 서비스 쿼리

````java
Properties props = new Properties();
props.put(StreamsConfig.APPLICATION_ID_CONFIG, "dev-consumer"); // 1
...

KafkaStreams streams = new KafkaStreams(builder, props); // 2
streams.start(); // 3

Runtime.getRuntime().addShutdownHook(new Thread(streams::close)); // 4

RestService service = new RestService(hostInfo, streams);
service.start(); // 5
````

1. 카프카 스트림즈 어플리케이션 설정
2. 토폴로지 실행 시, 사용할 새 KafkaStreams 인스턴스 생성
3. 카프카 스트림즈 어플리케이션 시작
4. 전역 셧다운 신호 감지 시, 카프카 스트림즈 셧다운 훅 추가
5. REST 서비스 실행

> 테스트 데이터 (65mph 초과 값)

- 4번 key 값의 레코드를 통해 희망 하는 전원 상태가 OFF 인 새로운 TurbineState 레코드 생성 후 셧다운 신호 생성
- reported-state-events 토픽으로 데이터 전송
- 디지털 트윈 서비스 쿼리 시 풍력 터빈의 보고한 상태 및 전원 상태가 OFF 로 설정돼 있는 희망하는 상태 레코드 조회 가능

````plaintext
1|{"timestamp": "...", "wind_speed_mph": 40, "power": "ON", "type": "REPORTED"}
2|{"timestamp": "...", "wind_speed_mph": 42, "power": "ON", "type": "REPORTED"}
3|{"timestamp": "...", "wind_speed_mph": 44, "power": "ON", "type": "REPORTED"}
4|{"timestamp": "...", "wind_speed_mph": 68, "power": "ON", "type": "REPORTED"}
````

> REST 요청 및 응답 예제

````curl
$ curl localhost:7000/devices/1 | jq '.'

{
  "desired": {
    "timestamp": "2020-11-23T09:02:01.000Z",
    "windSpeedMph": 68,
    "power": "OFF",
    "type": "DESIRED"
  },
  "reported": {
    "timestamp": "2020-11-23T09:02:01.000Z",
    "windSpeedMph": 68,
    "power": "ON",
    "type": "REPOTED"
  }
}
````


